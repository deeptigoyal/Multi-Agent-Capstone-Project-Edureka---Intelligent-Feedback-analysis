{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Design, implement, and demonstrate a complete multi-agent AI system that:\n",
        "1. Reads user feedback from CSV files containing app store reviews and support\n",
        "emails\n",
        "2. Classifies content into categories (Bug / Feature Request / Praise / Complaint /\n",
        "Spam)\n",
        "3. Extracts actionable insights and technical details\n",
        "4. Creates structured tickets and logs them to CSV files with appropriate priority\n",
        "levels and metadata\n",
        "5. Ensures quality and consistency through automated review\n",
        "\n",
        "Note: All outputs are derived solely from the CSV input (feedback text and metadata coming from csv only). The LLM does not fetch external data; it only classifies into different categories, interprets, and structures the given text using language understanding, ensuring no external knowledge sources influence the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {},
      "outputs": [],
      "source": [
        "#import streamlit as st\n",
        "import pandas as pd\n",
        "import asyncio\n",
        "from langgraph.graph import StateGraph\n",
        "from langchain_groq import ChatGroq\n",
        "from typing import TypedDict, Optional, Dict, List\n",
        "import re\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import requests\n",
        "import logging\n",
        "\n",
        "# === CONFIG ===\n",
        "load_dotenv()\n",
        "#GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
        "GROQ_API_KEY = \"7AlZuAPJX8f4D7J9cDWGdyb3FY33pbbdekjY9h1dDBYigyd6E9\"\n",
        "#ALPHA_VANTAGE_API_KEY = os.getenv(\"ALPHA_VANTAGE_API_KEY\")\n",
        "\n",
        "# # Setup logging : basic logging on terminal\n",
        "# logging.basicConfig(level=logging.INFO)\n",
        "# logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "import logging\n",
        "from logging.handlers import RotatingFileHandler\n",
        "\n",
        "logger = logging.getLogger(\"feedback_pipeline\")\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "if not logger.handlers:   # IMPORTANT\n",
        "    file_handler = RotatingFileHandler(\n",
        "        \"feedback_pipeline.log\",\n",
        "        maxBytes=5_000_000,\n",
        "        backupCount=3\n",
        "    )\n",
        "\n",
        "    formatter = logging.Formatter(\n",
        "        \"%(asctime)s - %(levelname)s - %(name)s - %(message)s\"\n",
        "    )\n",
        "    file_handler.setFormatter(formatter)\n",
        "\n",
        "    logger.addHandler(file_handler)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# === LLM ===\n",
        "\n",
        "llm = ChatGroq(groq_api_key=GROQ_API_KEY, model_name=\"llama-3.1-8b-instant\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# === CONSTANTS ===\n",
        "INTENT_DETECTION_NODE = \"Intent Detection\"\n",
        "\n",
        "# === STATE ===\n",
        "################################Changed##############################\n",
        "\n",
        "class FeedbackState(TypedDict):\n",
        "    # === INPUT ===\n",
        "    source_id: str                    # review_id or email_id\n",
        "    source_type: str                  # \"app_review\" | \"support_email\"\n",
        "    raw_text: str                     # review_text or email body/subject\n",
        "    metadata: Dict[str, str]          # platform, rating, timestamp, app_version, sender, etc.\n",
        "\n",
        "    # === FEEDBACK CLASSIFICATION ===\n",
        "    category: Optional[str]           # Bug | Feature Request | Praise | Complaint | Spam\n",
        "    confidence: Optional[float]       # Classification confidence score\n",
        "    priority: Optional[str]           # Critical | High | Medium | Low\n",
        "\n",
        "    # === BUG/Feature ANALYSIS OUTPUT ===\n",
        "    technical_details: Optional[str]  # For bugs: device, OS, repro steps, severity\n",
        "    feature_details: Optional[str]    # For features: description, impact, demand\n",
        "    analysis_notes: Optional[str]     # Agent reasoning / observations\n",
        "\n",
        "    # === TICKET CREATION ===\n",
        "    ticket_title: Optional[str]       # Suggested ticket title\n",
        "    ticket_description: Optional[str] # Structured ticket body\n",
        "    ticket_metadata: Optional[Dict[str, str]]  # tags, component, version, etc.\n",
        "\n",
        "    # === QUALITY CONTROL ===\n",
        "    qc_status: Optional[str]          # Approved | Needs Review | Rejected\n",
        "    qc_feedback: Optional[str]        # Critic agent comments\n",
        "\n",
        "    # === CONTROL & TRACEABILITY ===\n",
        "    manual_review_flag: Optional[bool]  # Human-in-the-loop trigger\n",
        "    processing_log: Optional[List[str]] # Step-by-step processing history\n",
        "\n",
        "\n",
        "\n",
        "# === USER PROFILE COLLECTION ===\n",
        "# PATTERN: ReAct (LLM extraction = Reason → Update profile = Action)\n",
        "# MODULE: Perception + Learning (extracts missing profile info)\n",
        "#async def csv_reader_agent(state: FeedbackState) -> FeedbackState:\n",
        "#    return state\n",
        "\n",
        "def csv_reader_agent(\n",
        "    file_path: str,\n",
        "    source_type: str\n",
        ") -> List[FeedbackState]:\n",
        "    \"\"\"\n",
        "    Reads feedback CSV and converts each row into FeedbackState.\n",
        "    source_type: 'review' or 'email' \n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_csv(file_path)\n",
        "    print(f'\\nThe column names in this csv {file_path} are-->', df.columns)\n",
        "    feedback_states: List[FeedbackState] = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        if source_type == \"review\":\n",
        "            raw_text = row.get(\"review_text\", \"\")\n",
        "            source_id = str(row.get(\"review_id\"))\n",
        "        else:  # support email\n",
        "            raw_text = f\"{row.get('subject', '')}. {row.get('body', '')}\"\n",
        "            source_id = str(row.get(\"email_id\"))\n",
        "\n",
        "        state: FeedbackState = {\n",
        "            \"input_filename\": file_path,\n",
        "            \"source_id\": source_id,\n",
        "            \"source_type\": source_type,\n",
        "            \"raw_text\": raw_text,\n",
        "\n",
        "            \"category\": None,\n",
        "            \"confidence\": None,\n",
        "            \"priority\": None,\n",
        "\n",
        "            \"technical_details\": None,\n",
        "            \"feature_details\": None,\n",
        "\n",
        "            \"ticket_title\": None,\n",
        "            \"ticket_description\": None,\n",
        "\n",
        "            \"manual_review_flag\": False,\n",
        "            \"qc_feedback\": [],\n",
        "\n",
        "            \"processing_log\": [\n",
        "                f\"CSV Reader: Loaded {source_type} record {source_id}\"\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        feedback_states.append(state)\n",
        "\n",
        "    logger.info(\n",
        "        f\"Loaded {len(feedback_states)} records from {file_path} as {source_type}\"\n",
        "    )\n",
        "    print('\\n feedback state is/are -->',feedback_states)\n",
        "    return feedback_states\n",
        "\n",
        "\n",
        "\n",
        "#async def feedback_classifier_agent(state: FeedbackState) -> FeedbackState:\n",
        "#    return state\n",
        "\n",
        "# === FEEDBACK CLASSIFIER AGENT ===\n",
        "async def feedback_classifier_agent(state: FeedbackState) -> FeedbackState:\n",
        "    raw_text = state.get(\"raw_text\", \"\")\n",
        "    metadata = state.get(\"metadata\", {})\n",
        "\n",
        "    print('Raw text is -->',raw_text)\n",
        "    print('Metadat is--->', metadata)\n",
        "\n",
        "\n",
        "    processing_log: List[str] = state.get(\"processing_log\", [])\n",
        "\n",
        "    # --- LLM Prompt ---\n",
        "    prompt = (\n",
        "        f\"Classify the following user feedback into one of: \"\n",
        "        f\"'Bug', 'Feature Request', 'Praise', 'Complaint', 'Spam'. \"\n",
        "        f\"Provide a confidence score (0-1) and suggest an initial priority \"\n",
        "        f\"(Critical, High, Medium, Low).\\n\\n\"\n",
        "        f\"Feedback: {raw_text}\\n\"\n",
        "        f\"Metadata: {metadata}\\n\\n\"\n",
        "        f\"Format: category: <category>\\n\"\n",
        "        f\"confidence: <0-1>\\n\"\n",
        "        f\"priority: <priority>\\n\"\n",
        "    )\n",
        "\n",
        "    # --- Call LLM ---\n",
        "    response = await llm.ainvoke(prompt)\n",
        "    message = response.content.strip()\n",
        "    processing_log.append(f\"Classifier prompt: {prompt}\")\n",
        "    processing_log.append(f\"Classifier response: {message}\")\n",
        "\n",
        "    # --- Parse LLM response ---\n",
        "    category_match = re.search(r\"category:\\s*(\\w+)\", message, re.IGNORECASE)\n",
        "    confidence_match = re.search(r\"confidence:\\s*([0-1]\\.?\\d*)\", message)\n",
        "    priority_match = re.search(r\"priority:\\s*(\\w+)\", message, re.IGNORECASE)\n",
        "\n",
        "    category = category_match.group(1) if category_match else \"Unknown\"\n",
        "    confidence = float(confidence_match.group(1)) if confidence_match else None\n",
        "    priority = priority_match.group(1) if priority_match else \"Medium\"\n",
        "\n",
        "    # --- Update state ---\n",
        "    state.update({\n",
        "        \"category\": category,\n",
        "        \"confidence\": confidence,\n",
        "        \"priority\": priority,\n",
        "        \"processing_log\": processing_log\n",
        "    })\n",
        "\n",
        "    return state\n",
        "\n",
        "#async def bug_analysis_agent(state: FeedbackState) -> FeedbackState:\n",
        "#    return state\n",
        "\n",
        "async def bug_analysis_agent(state: FeedbackState) -> FeedbackState:\n",
        "    if state.get(\"category\") != \"Bug\":\n",
        "        # Skip if not a bug\n",
        "        return state\n",
        "\n",
        "    raw_text = state.get(\"raw_text\", \"\")\n",
        "    metadata = state.get(\"metadata\", {})\n",
        "\n",
        "    print('\\n Raw Data',raw_text)\n",
        "    print('\\n Metadata',metadata)\n",
        "\n",
        "    processing_log: List[str] = state.get(\"processing_log\", [])\n",
        "\n",
        "    # --- LLM Prompt ---\n",
        "    prompt = (\n",
        "        f\"Analyze this bug report and extract technical details:\\n\"\n",
        "        f\"- Device/OS information\\n\"\n",
        "        f\"- Steps to reproduce\\n\"\n",
        "        f\"- Severity (Critical/High/Medium/Low)\\n\"\n",
        "        f\"Provide the output in structured format.\\n\\n\"\n",
        "        f\"Feedback: {raw_text}\\n\"\n",
        "        f\"Metadata: {metadata}\\n\"\n",
        "        f\"Format:\\n\"\n",
        "        f\"device_info: <device info>\\n\"\n",
        "        f\"os_version: <OS info>\\n\"\n",
        "        f\"steps_to_reproduce: <steps>\\n\"\n",
        "        f\"severity: <severity>\\n\"\n",
        "    )\n",
        "\n",
        "    response = await llm.ainvoke(prompt)\n",
        "    message = response.content.strip()\n",
        "\n",
        "    processing_log.append(f\"Bug Analysis prompt: {prompt}\")\n",
        "    processing_log.append(f\"Bug Analysis response: {message}\")\n",
        "\n",
        "    # --- Parse LLM response ---\n",
        "    device_info_match = re.search(r\"device_info:\\s*(.*)\", message)\n",
        "    os_version_match = re.search(r\"os_version:\\s*(.*)\", message)\n",
        "    steps_match = re.search(r\"steps_to_reproduce:\\s*(.*)\", message)\n",
        "    severity_match = re.search(r\"severity:\\s*(.*)\", message, re.IGNORECASE)\n",
        "\n",
        "    technical_details = {\n",
        "        \"device_info\": device_info_match.group(1) if device_info_match else \"\",\n",
        "        \"os_version\": os_version_match.group(1) if os_version_match else \"\",\n",
        "        \"steps_to_reproduce\": steps_match.group(1) if steps_match else \"\",\n",
        "    }\n",
        "\n",
        "    priority = severity_match.group(1) if severity_match else state.get(\"priority\", \"Medium\")\n",
        "\n",
        "    # --- Update state ---\n",
        "    state.update({\n",
        "        \"technical_details\": technical_details,\n",
        "        \"priority\": priority,\n",
        "        \"processing_log\": processing_log\n",
        "    })\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "#async def feature_extraction_agent(state: FeedbackState) -> FeedbackState:\n",
        "#    return state\n",
        "async def feature_extraction_agent(state: FeedbackState) -> FeedbackState:\n",
        "    if state.get(\"category\") != \"Feature Request\":\n",
        "        # Skip if not a feature request\n",
        "        return state\n",
        "\n",
        "    raw_text = state.get(\"raw_text\", \"\")\n",
        "    metadata = state.get(\"metadata\", {})\n",
        "    processing_log: List[str] = state.get(\"processing_log\", [])\n",
        "\n",
        "    # --- LLM Prompt ---\n",
        "    prompt = (\n",
        "        f\"Analyze this feature request and extract actionable details:\\n\"\n",
        "        f\"- Feature description\\n\"\n",
        "        f\"- User intent / goal\\n\"\n",
        "        f\"- Estimated user impact / demand\\n\"\n",
        "        f\"Provide the output in structured format.\\n\\n\"\n",
        "        f\"Feedback: {raw_text}\\n\"\n",
        "        f\"Metadata: {metadata}\\n\"\n",
        "        f\"Format:\\n\"\n",
        "        f\"feature_description: <description>\\n\"\n",
        "        f\"user_intent: <intent>\\n\"\n",
        "        f\"user_impact: <high/medium/low>\\n\"\n",
        "    )\n",
        "\n",
        "    # --- Call LLM ---\n",
        "    response = await llm.ainvoke(prompt)\n",
        "    message = response.content.strip()\n",
        "\n",
        "    processing_log.append(f\"Feature Extraction prompt: {prompt}\")\n",
        "    processing_log.append(f\"Feature Extraction response: {message}\")\n",
        "\n",
        "    # --- Parse LLM response ---\n",
        "    description_match = re.search(r\"feature_description:\\s*(.*)\", message)\n",
        "    intent_match = re.search(r\"user_intent:\\s*(.*)\", message)\n",
        "    impact_match = re.search(r\"user_impact:\\s*(.*)\", message, re.IGNORECASE)\n",
        "\n",
        "    feature_details = {\n",
        "        \"feature_description\": description_match.group(1) if description_match else \"\",\n",
        "        \"user_intent\": intent_match.group(1) if intent_match else \"\",\n",
        "        \"user_impact\": impact_match.group(1) if impact_match else \"Medium\"\n",
        "    }\n",
        "\n",
        "    # --- Update state ---\n",
        "    state.update({\n",
        "        \"feature_details\": feature_details,\n",
        "        \"processing_log\": processing_log\n",
        "    })\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "\n",
        "#async def ticket_creation_agent(state: FeedbackState) -> FeedbackState:\n",
        "#    return state\n",
        "\n",
        "#ticket agent which combines outputs from Bug Analysis or Feature Extraction into structured tickets.\n",
        "async def ticket_creation_agent(state: FeedbackState) -> FeedbackState:\n",
        "    category = state.get(\"category\", \"\")\n",
        "    priority = state.get(\"priority\", \"Medium\")\n",
        "    technical_details = state.get(\"technical_details\", {})\n",
        "    feature_details = state.get(\"feature_details\", {})\n",
        "    processing_log: List[str] = state.get(\"processing_log\", [])\n",
        "\n",
        "    # --- Construct ticket ---\n",
        "    if category == \"Bug\":\n",
        "        ticket_title = f\"[BUG] {technical_details.get('device_info', '')} - Issue\"\n",
        "        ticket_description = (\n",
        "            f\"Category: {category}\\n\"\n",
        "            f\"Priority: {priority}\\n\"\n",
        "            f\"Device Info: {technical_details.get('device_info', '')}\\n\"\n",
        "            f\"OS Version: {technical_details.get('os_version', '')}\\n\"\n",
        "            f\"Steps to Reproduce: {technical_details.get('steps_to_reproduce', '')}\\n\"\n",
        "        )\n",
        "    elif category == \"Feature Request\":\n",
        "        ticket_title = f\"[FEATURE REQUEST] {feature_details.get('feature_description', '')[:50]}\"\n",
        "        ticket_description = (\n",
        "            f\"Category: {category}\\n\"\n",
        "            f\"Priority: {priority}\\n\"\n",
        "            f\"Feature Description: {feature_details.get('feature_description', '')}\\n\"\n",
        "            f\"User Intent: {feature_details.get('user_intent', '')}\\n\"\n",
        "            f\"Estimated User Impact: {feature_details.get('user_impact', 'Medium')}\\n\"\n",
        "        )\n",
        "    else:\n",
        "        ticket_title = f\"[{category.upper()}] Feedback\"\n",
        "        ticket_description = f\"Category: {category}\\nPriority: {priority}\\n\"\n",
        "\n",
        "    # Include metadata\n",
        "    metadata = state.get(\"metadata\", {})\n",
        "    for key, value in metadata.items():\n",
        "        ticket_description += f\"{key}: {value}\\n\"\n",
        "\n",
        "    processing_log.append(f\"Ticket Created: {ticket_title}\")\n",
        "\n",
        "    import csv\n",
        "    from typing import List\n",
        "    # --- CSV Logging ---\n",
        "    ticket_row = {\n",
        "        \"ticket_title\": ticket_title,\n",
        "        \"ticket_description\": ticket_description,\n",
        "        \"category\": category,\n",
        "        \"priority\": priority,\n",
        "        \"technical_details\": str(technical_details),\n",
        "        \"feature_details\": str(feature_details),\n",
        "        \"metadata\": str(metadata)\n",
        "    }\n",
        "\n",
        "    #csv_file = f\"generated_tickets_\" + state[\"input_filename\"]\n",
        "    csv_file = f\"generated_tickets.csv\"\n",
        "    fieldnames = list(ticket_row.keys())\n",
        "\n",
        "    # Append to CSV (write header if empty)\n",
        "    with open(csv_file, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
        "        if f.tell() == 0:\n",
        "            writer.writeheader()\n",
        "        writer.writerow(ticket_row)\n",
        "\n",
        "\n",
        "    # --- Update state ---\n",
        "    state.update({\n",
        "        \"ticket_title\": ticket_title,\n",
        "        \"ticket_description\": ticket_description,\n",
        "        \"ticket_metadata\": metadata,\n",
        "        \"processing_log\": processing_log\n",
        "    })\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#async def quality_critic_agent(state: FeedbackState) -> FeedbackState:\n",
        "#    return state\n",
        "\n",
        "#Quality Critic Agent, which validates ticket completeness, accuracy, and flags for human review if needed.\n",
        "async def quality_critic_agent(state: FeedbackState) -> FeedbackState:\n",
        "    ticket_title = state.get(\"ticket_title\", \"\")\n",
        "    ticket_description = state.get(\"ticket_description\", \"\")\n",
        "    category = state.get(\"category\", \"\")\n",
        "    confidence = state.get(\"confidence\", 1.0)\n",
        "    processing_log: List[str] = state.get(\"processing_log\", [])\n",
        "\n",
        "    manual_review_flag = False\n",
        "    qc_feedback = []\n",
        "\n",
        "    # --- Basic checks ---\n",
        "    if not ticket_title:\n",
        "        manual_review_flag = True\n",
        "        qc_feedback.append(\"Ticket title missing.\")\n",
        "    if not ticket_description:\n",
        "        manual_review_flag = True\n",
        "        qc_feedback.append(\"Ticket description missing.\")\n",
        "    if category in [\"Bug\", \"Feature Request\"] and confidence is not None and confidence < 0.7:\n",
        "        manual_review_flag = True\n",
        "        qc_feedback.append(f\"Low confidence ({confidence}) for category {category}.\")\n",
        "\n",
        "    if manual_review_flag:\n",
        "        processing_log.append(f\"Quality Critic flagged manual review: {qc_feedback}\")\n",
        "    else:\n",
        "        processing_log.append(\"Quality Critic passed: ticket looks complete.\")\n",
        "\n",
        "    # --- Update state ---\n",
        "    state.update({\n",
        "        \"manual_review_flag\": manual_review_flag,\n",
        "        \"qc_feedback\": qc_feedback,\n",
        "        \"processing_log\": processing_log\n",
        "    })\n",
        "\n",
        "    return state\n",
        "\n",
        "async def end_node(state: FeedbackState) -> FeedbackState:\n",
        "    return state\n",
        "\n",
        "\n",
        "# === BUILD GRAPH ===\n",
        "# PATTERN: Planning Pattern — router decides next node\n",
        "# MODULE: Cognition\n",
        "def get_next_node(state: FeedbackState) -> str:\n",
        "    if state.get(\"manual_review_flag\"):\n",
        "        return \"Human Review\"\n",
        "\n",
        "    category = state.get(\"category\")\n",
        "\n",
        "    if category == \"Bug\":\n",
        "        return \"Bug Analysis\"\n",
        "    elif category == \"Feature Request\":\n",
        "        return \"Feature Extraction\"\n",
        "    elif category in [\"Praise\", \"Complaint\"]:\n",
        "        return \"Ticket Creation\"\n",
        "    elif category == \"Spam\":\n",
        "        return \"End\"\n",
        "    else:\n",
        "        return \"End\"\n",
        "\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# run csv reader agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:feedback_pipeline:Loaded 14 records from app_store_reviews.csv as review\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "The column names in this csv app_store_reviews.csv are--> Index(['review_id', 'platform', 'rating', 'review_text', 'user_name', 'date',\n",
            "       'app_version'],\n",
            "      dtype='object')\n",
            "\n",
            " feedback state is/are --> [{'input_filename': 'app_store_reviews.csv', 'source_id': 'R001', 'source_type': 'review', 'raw_text': 'App crashes when I try to open my task list after the latest update.', 'category': None, 'confidence': None, 'priority': None, 'technical_details': None, 'feature_details': None, 'ticket_title': None, 'ticket_description': None, 'manual_review_flag': False, 'qc_feedback': [], 'processing_log': ['CSV Reader: Loaded review record R001']}, {'input_filename': 'app_store_reviews.csv', 'source_id': 'R002', 'source_type': 'review', 'raw_text': \"Can't login since update. Keeps showing an error on iOS 17.\", 'category': None, 'confidence': None, 'priority': None, 'technical_details': None, 'feature_details': None, 'ticket_title': None, 'ticket_description': None, 'manual_review_flag': False, 'qc_feedback': [], 'processing_log': ['CSV Reader: Loaded review record R002']}, {'input_filename': 'app_store_reviews.csv', 'source_id': 'R003', 'source_type': 'review', 'raw_text': 'Data sync not working between my phone and tablet.', 'category': None, 'confidence': None, 'priority': None, 'technical_details': None, 'feature_details': None, 'ticket_title': None, 'ticket_description': None, 'manual_review_flag': False, 'qc_feedback': [], 'processing_log': ['CSV Reader: Loaded review record R003']}, {'input_filename': 'app_store_reviews.csv', 'source_id': 'R004', 'source_type': 'review', 'raw_text': 'Please add a dark mode. Would be very helpful at night.', 'category': None, 'confidence': None, 'priority': None, 'technical_details': None, 'feature_details': None, 'ticket_title': None, 'ticket_description': None, 'manual_review_flag': False, 'qc_feedback': [], 'processing_log': ['CSV Reader: Loaded review record R004']}, {'input_filename': 'app_store_reviews.csv', 'source_id': 'R005', 'source_type': 'review', 'raw_text': 'Would love to see calendar integration in future updates.', 'category': None, 'confidence': None, 'priority': None, 'technical_details': None, 'feature_details': None, 'ticket_title': None, 'ticket_description': None, 'manual_review_flag': False, 'qc_feedback': [], 'processing_log': ['CSV Reader: Loaded review record R005']}, {'input_filename': 'app_store_reviews.csv', 'source_id': 'R006', 'source_type': 'review', 'raw_text': 'Amazing app! Love the new reminder feature.', 'category': None, 'confidence': None, 'priority': None, 'technical_details': None, 'feature_details': None, 'ticket_title': None, 'ticket_description': None, 'manual_review_flag': False, 'qc_feedback': [], 'processing_log': ['CSV Reader: Loaded review record R006']}, {'input_filename': 'app_store_reviews.csv', 'source_id': 'R007', 'source_type': 'review', 'raw_text': 'Works perfectly for daily planning. Great experience overall.', 'category': None, 'confidence': None, 'priority': None, 'technical_details': None, 'feature_details': None, 'ticket_title': None, 'ticket_description': None, 'manual_review_flag': False, 'qc_feedback': [], 'processing_log': ['CSV Reader: Loaded review record R007']}, {'input_filename': 'app_store_reviews.csv', 'source_id': 'R008', 'source_type': 'review', 'raw_text': 'App is very slow and takes too long to load tasks.', 'category': None, 'confidence': None, 'priority': None, 'technical_details': None, 'feature_details': None, 'ticket_title': None, 'ticket_description': None, 'manual_review_flag': False, 'qc_feedback': [], 'processing_log': ['CSV Reader: Loaded review record R008']}, {'input_filename': 'app_store_reviews.csv', 'source_id': 'R009', 'source_type': 'review', 'raw_text': 'Too expensive for basic features. Not worth the price.', 'category': None, 'confidence': None, 'priority': None, 'technical_details': None, 'feature_details': None, 'ticket_title': None, 'ticket_description': None, 'manual_review_flag': False, 'qc_feedback': [], 'processing_log': ['CSV Reader: Loaded review record R009']}, {'input_filename': 'app_store_reviews.csv', 'source_id': 'R010', 'source_type': 'review', 'raw_text': 'Poor customer service. No response to my emails.', 'category': None, 'confidence': None, 'priority': None, 'technical_details': None, 'feature_details': None, 'ticket_title': None, 'ticket_description': None, 'manual_review_flag': False, 'qc_feedback': [], 'processing_log': ['CSV Reader: Loaded review record R010']}, {'input_filename': 'app_store_reviews.csv', 'source_id': 'R011', 'source_type': 'review', 'raw_text': 'Love the clean UI and simple design. Works perfectly!', 'category': None, 'confidence': None, 'priority': None, 'technical_details': None, 'feature_details': None, 'ticket_title': None, 'ticket_description': None, 'manual_review_flag': False, 'qc_feedback': [], 'processing_log': ['CSV Reader: Loaded review record R011']}, {'input_filename': 'app_store_reviews.csv', 'source_id': 'R012', 'source_type': 'review', 'raw_text': 'Missing functionality like recurring task templates.', 'category': None, 'confidence': None, 'priority': None, 'technical_details': None, 'feature_details': None, 'ticket_title': None, 'ticket_description': None, 'manual_review_flag': False, 'qc_feedback': [], 'processing_log': ['CSV Reader: Loaded review record R012']}, {'input_filename': 'app_store_reviews.csv', 'source_id': 'R013', 'source_type': 'review', 'raw_text': 'asdfghjkl qwerty uiop 123456', 'category': None, 'confidence': None, 'priority': None, 'technical_details': None, 'feature_details': None, 'ticket_title': None, 'ticket_description': None, 'manual_review_flag': False, 'qc_feedback': [], 'processing_log': ['CSV Reader: Loaded review record R013']}, {'input_filename': 'app_store_reviews.csv', 'source_id': 'R014', 'source_type': 'review', 'raw_text': 'Visit www.bestappsfree.com for amazing deals!!!', 'category': None, 'confidence': None, 'priority': None, 'technical_details': None, 'feature_details': None, 'ticket_title': None, 'ticket_description': None, 'manual_review_flag': False, 'qc_feedback': [], 'processing_log': ['CSV Reader: Loaded review record R014']}]\n",
            "STEP 1: RAW INPUT\n",
            "App crashes when I try to open my task list after the latest update.\n"
          ]
        }
      ],
      "source": [
        "states =  csv_reader_agent(\"app_store_reviews.csv\", \"review\")\n",
        "\n",
        "state = states[0]  # pick one record\n",
        "\n",
        "print(\"STEP 1: RAW INPUT\")\n",
        "print(state[\"raw_text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Feedback classifier Agent\n",
        "\n",
        "#Note: becase function is async that is parallel processing so await keyword required\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw text is --> App crashes when I try to open my task list after the latest update.\n",
            "Metadat is---> {}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "STEP 2: CLASSIFICATION\n",
            "{'input_filename': 'app_store_reviews.csv', 'source_id': 'R001', 'source_type': 'review', 'raw_text': 'App crashes when I try to open my task list after the latest update.', 'category': 'Bug', 'confidence': 1.0, 'priority': 'Critical', 'technical_details': None, 'feature_details': None, 'ticket_title': None, 'ticket_description': None, 'manual_review_flag': False, 'qc_feedback': [], 'processing_log': ['CSV Reader: Loaded review record R001', \"Classifier prompt: Classify the following user feedback into one of: 'Bug', 'Feature Request', 'Praise', 'Complaint', 'Spam'. Provide a confidence score (0-1) and suggest an initial priority (Critical, High, Medium, Low).\\n\\nFeedback: App crashes when I try to open my task list after the latest update.\\nMetadata: {}\\n\\nFormat: category: <category>\\nconfidence: <0-1>\\npriority: <priority>\\n\", 'Classifier response: category: Bug\\nconfidence: 1\\npriority: Critical\\n\\nThe user is reporting an issue where the app crashes, which is a severe problem that prevents the user from using the app. This indicates a high priority for fixing the bug.']}\n",
            "State is -> Bug & confidence is 1.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "state = await feedback_classifier_agent(state)\n",
        "print(\"\\nSTEP 2: CLASSIFICATION\")\n",
        "\n",
        "print(state)\n",
        "\n",
        "print('State is ->',state[\"category\"],'& confidence is', state[\"confidence\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conditional Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Raw Data App crashes when I try to open my task list after the latest update.\n",
            "\n",
            " Metadata {}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Bug details: {'device_info': '', 'os_version': '', 'steps_to_reproduce': ''}\n"
          ]
        }
      ],
      "source": [
        "# STEP 3: Conditional analysis\n",
        "if state[\"category\"] == \"Bug\":\n",
        "    state = await bug_analysis_agent(state)\n",
        "    print(\"\\nBug details:\", state[\"technical_details\"])\n",
        "\n",
        "elif state[\"category\"] == \"Feature Request\":\n",
        "    state = await feature_extraction_agent(state)\n",
        "    print(\"\\nFeature details:\", state[\"feature_details\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ticket Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "STEP 4: TICKET\n",
            "[BUG]  - Issue\n",
            "The state so far now is -->\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input_filename': 'app_store_reviews.csv',\n",
              " 'source_id': 'R001',\n",
              " 'source_type': 'review',\n",
              " 'raw_text': 'App crashes when I try to open my task list after the latest update.',\n",
              " 'category': 'Bug',\n",
              " 'confidence': 1.0,\n",
              " 'priority': 'High (since the app crashes, causing inconvenience to the user and potentially data loss)',\n",
              " 'technical_details': {'device_info': '',\n",
              "  'os_version': '',\n",
              "  'steps_to_reproduce': ''},\n",
              " 'feature_details': None,\n",
              " 'ticket_title': '[BUG]  - Issue',\n",
              " 'ticket_description': 'Category: Bug\\nPriority: High (since the app crashes, causing inconvenience to the user and potentially data loss)\\nDevice Info: \\nOS Version: \\nSteps to Reproduce: \\n',\n",
              " 'manual_review_flag': False,\n",
              " 'qc_feedback': [],\n",
              " 'processing_log': ['CSV Reader: Loaded review record R001',\n",
              "  \"Classifier prompt: Classify the following user feedback into one of: 'Bug', 'Feature Request', 'Praise', 'Complaint', 'Spam'. Provide a confidence score (0-1) and suggest an initial priority (Critical, High, Medium, Low).\\n\\nFeedback: App crashes when I try to open my task list after the latest update.\\nMetadata: {}\\n\\nFormat: category: <category>\\nconfidence: <0-1>\\npriority: <priority>\\n\",\n",
              "  'Classifier response: category: Bug\\nconfidence: 1\\npriority: Critical\\n\\nThe user is reporting an issue where the app crashes, which is a severe problem that prevents the user from using the app. This indicates a high priority for fixing the bug.',\n",
              "  'Bug Analysis prompt: Analyze this bug report and extract technical details:\\n- Device/OS information\\n- Steps to reproduce\\n- Severity (Critical/High/Medium/Low)\\nProvide the output in structured format.\\n\\nFeedback: App crashes when I try to open my task list after the latest update.\\nMetadata: {}\\nFormat:\\ndevice_info: <device info>\\nos_version: <OS info>\\nsteps_to_reproduce: <steps>\\nseverity: <severity>\\n',\n",
              "  'Bug Analysis response: Based on the given bug report, here\\'s the extracted technical details in the requested format:\\n\\n```json\\n{\\n  \"device_info\": \"Device/OS not specified\",\\n  \"os_version\": \"OS not specified\",\\n  \"steps_to_reproduce\": \"Steps to reproduce not specified, only mentioned an app crashing after latest update\",\\n  \"severity\": \"High\"  # Assuming high severity since app crashes and can be inconvenient for users\\n}\\n```\\n\\nHowever, I can attempt to analyze it further and make some educated guesses about the device/OS information and steps to reproduce based on common scenarios.\\n\\n**Possible Device/OS Information**\\n- Device type: Mobile phone\\n- OS type: Android or iOS\\n- Specific device and OS versions are not provided.\\n\\n**Possible Steps to Reproduce**\\n1. Install the latest version of the app.\\n2. Open the app and navigate to the task list.\\n3. Try to access or view the task list.\\n\\n**Severity**\\n- Severity: High (since the app crashes, causing inconvenience to the user and potentially data loss)\\n\\nTo provide a more accurate analysis, it\\'s essential to have more detailed information from the user, such as their device and OS versions, and clear steps to reproduce the issue.',\n",
              "  'Ticket Created: [BUG]  - Issue'],\n",
              " 'ticket_metadata': {}}"
            ]
          },
          "execution_count": 240,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "state = await ticket_creation_agent(state)\n",
        "print(\"\\nSTEP 4: TICKET\")\n",
        "print(state[\"ticket_title\"])\n",
        "\n",
        "print('The state so far now is -->')\n",
        "state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "STEP 5: QC\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "state = await quality_critic_agent(state)\n",
        "print(\"\\nSTEP 5: QC\")\n",
        "print(state[\"qc_feedback\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_filename': 'app_store_reviews.csv',\n",
              " 'source_id': 'R001',\n",
              " 'source_type': 'review',\n",
              " 'raw_text': 'App crashes when I try to open my task list after the latest update.',\n",
              " 'category': 'Bug',\n",
              " 'confidence': 1.0,\n",
              " 'priority': 'High (since the app crashes, causing inconvenience to the user and potentially data loss)',\n",
              " 'technical_details': {'device_info': '',\n",
              "  'os_version': '',\n",
              "  'steps_to_reproduce': ''},\n",
              " 'feature_details': None,\n",
              " 'ticket_title': '[BUG]  - Issue',\n",
              " 'ticket_description': 'Category: Bug\\nPriority: High (since the app crashes, causing inconvenience to the user and potentially data loss)\\nDevice Info: \\nOS Version: \\nSteps to Reproduce: \\n',\n",
              " 'manual_review_flag': False,\n",
              " 'qc_feedback': [],\n",
              " 'processing_log': ['CSV Reader: Loaded review record R001',\n",
              "  \"Classifier prompt: Classify the following user feedback into one of: 'Bug', 'Feature Request', 'Praise', 'Complaint', 'Spam'. Provide a confidence score (0-1) and suggest an initial priority (Critical, High, Medium, Low).\\n\\nFeedback: App crashes when I try to open my task list after the latest update.\\nMetadata: {}\\n\\nFormat: category: <category>\\nconfidence: <0-1>\\npriority: <priority>\\n\",\n",
              "  'Classifier response: category: Bug\\nconfidence: 1\\npriority: Critical\\n\\nThe user is reporting an issue where the app crashes, which is a severe problem that prevents the user from using the app. This indicates a high priority for fixing the bug.',\n",
              "  'Bug Analysis prompt: Analyze this bug report and extract technical details:\\n- Device/OS information\\n- Steps to reproduce\\n- Severity (Critical/High/Medium/Low)\\nProvide the output in structured format.\\n\\nFeedback: App crashes when I try to open my task list after the latest update.\\nMetadata: {}\\nFormat:\\ndevice_info: <device info>\\nos_version: <OS info>\\nsteps_to_reproduce: <steps>\\nseverity: <severity>\\n',\n",
              "  'Bug Analysis response: Based on the given bug report, here\\'s the extracted technical details in the requested format:\\n\\n```json\\n{\\n  \"device_info\": \"Device/OS not specified\",\\n  \"os_version\": \"OS not specified\",\\n  \"steps_to_reproduce\": \"Steps to reproduce not specified, only mentioned an app crashing after latest update\",\\n  \"severity\": \"High\"  # Assuming high severity since app crashes and can be inconvenient for users\\n}\\n```\\n\\nHowever, I can attempt to analyze it further and make some educated guesses about the device/OS information and steps to reproduce based on common scenarios.\\n\\n**Possible Device/OS Information**\\n- Device type: Mobile phone\\n- OS type: Android or iOS\\n- Specific device and OS versions are not provided.\\n\\n**Possible Steps to Reproduce**\\n1. Install the latest version of the app.\\n2. Open the app and navigate to the task list.\\n3. Try to access or view the task list.\\n\\n**Severity**\\n- Severity: High (since the app crashes, causing inconvenience to the user and potentially data loss)\\n\\nTo provide a more accurate analysis, it\\'s essential to have more detailed information from the user, such as their device and OS versions, and clear steps to reproduce the issue.',\n",
              "  'Ticket Created: [BUG]  - Issue',\n",
              "  'Quality Critic passed: ticket looks complete.'],\n",
              " 'ticket_metadata': {}}"
            ]
          },
          "execution_count": 242,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # OR creating whole pipleine \n",
        "\n",
        "# async def debug_pipeline():\n",
        "#     states = csv_reader_agent(\"app_store_reviews.csv\", \"review\")\n",
        "#     state = states[0]\n",
        "\n",
        "#     print(\"STEP 1: RAW INPUT\")\n",
        "#     print(state[\"raw_text\"])\n",
        "\n",
        "#     state = await feedback_classifier_agent(state)\n",
        "#     print(\"\\nSTEP 2: CLASSIFICATION\")\n",
        "#     print(state[\"category\"], state[\"confidence\"])\n",
        "\n",
        "#     if state[\"category\"] == \"Bug\":\n",
        "#         state = await bug_analysis_agent(state)\n",
        "#         print(\"\\nSTEP 3: BUG ANALYSIS\")\n",
        "#         print(state[\"technical_details\"])\n",
        "\n",
        "#     if state[\"category\"] == \"Feature Request\":\n",
        "#         state = await feature_extraction_agent(state)\n",
        "#         print(\"\\nSTEP 3: FEATURE EXTRACTION\")\n",
        "#         print(state[\"feature_details\"])\n",
        "\n",
        "#     state = await ticket_creation_agent(state)\n",
        "#     print(\"\\nSTEP 4: TICKET\")\n",
        "#     print(state[\"ticket_title\"])\n",
        "\n",
        "#     state = await quality_critic_agent(state)\n",
        "#     print(\"\\nSTEP 5: QC\")\n",
        "#     print(state[\"qc_feedback\"])\n",
        "\n",
        "# # Run it\n",
        "# await debug_pipeline()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Graph Builder / Orchestration step in LangGraph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "builder = StateGraph(FeedbackState)\n",
        "\n",
        "# PATTERN: Planning — adds modular nodes\n",
        "# Add nodes\n",
        "builder.add_node(\"CSV Reader\", csv_reader_agent)\n",
        "builder.add_node(\"Feedback Classifier\", feedback_classifier_agent)\n",
        "builder.add_node(\"Bug Analysis\", bug_analysis_agent)\n",
        "builder.add_node(\"Feature Extraction\", feature_extraction_agent)\n",
        "builder.add_node(\"Ticket Creation\", ticket_creation_agent)\n",
        "builder.add_node(\"Quality Critic\", quality_critic_agent)\n",
        "builder.add_node(\"End\", end_node)\n",
        "\n",
        "# PATTERN: Planning + ReAct orchestration (routing based on reasoning)\n",
        "# Entry point #we can \n",
        "#Note: This decides the entry point for builder . Cell 93 will exceute everythign from here \n",
        "#builder.set_entry_point(\"CSV Reader\")\n",
        "builder.set_entry_point(\"Feedback Classifier\")\n",
        "\n",
        "# Edges\n",
        "builder.add_edge(\"CSV Reader\", \"Feedback Classifier\")\n",
        "\n",
        "#This defines dynamic routing in the graph. After the Feedback Classifier runs, get_next_node examines \n",
        "# the state and decides which agent should run next (Bug Analysis, Feature Extraction, Ticket Creation, or End),\n",
        "# based on the classified feedback category.\n",
        "#In this conditional edge, if get_next_node returns \"Bug Analysis\", the graph moves to the Bug Analysis node; \n",
        "# if it returns \"Feature Extraction\", it goes there. Keys are decision outputs, values are destination nodes.\n",
        "\n",
        "builder.add_conditional_edges(\n",
        "    \"Feedback Classifier\",\n",
        "    get_next_node,\n",
        "    {\n",
        "        \"Bug Analysis\": \"Bug Analysis\",\n",
        "        \"Feature Extraction\": \"Feature Extraction\",\n",
        "        \"Ticket Creation\": \"Ticket Creation\",\n",
        "        \"End\": \"End\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# Post-analysis flow\n",
        "builder.add_edge(\"Bug Analysis\", \"Ticket Creation\")\n",
        "builder.add_edge(\"Feature Extraction\", \"Ticket Creation\")\n",
        "builder.add_edge(\"Ticket Creation\", \"Quality Critic\")\n",
        "builder.add_edge(\"Quality Critic\", \"End\")\n",
        "\n",
        "feedback_graph = builder.compile()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {},
      "outputs": [],
      "source": [
        "#✔️ astream() only takes state (and optional config), not node inputs.\n",
        "#async for event in feedback_graph.astream(state):\n",
        "#    print(event)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Runner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:feedback_pipeline:Loaded 9 records from support_emails.csv as email\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "The column names in this csv support_emails.csv are--> Index(['email_id', 'subject', 'body', 'sender_email', 'timestamp', 'priority'], dtype='object')\n",
            "\n",
            " feedback state is/are --> [{'input_filename': 'support_emails.csv', 'source_id': 'E001', 'source_type': 'email', 'raw_text': 'App Crash Report. Dear Team, the app crashes on my Samsung Galaxy S21 running Android 14. Steps: Open app → tap Add Task → crash.', 'category': None, 'confidence': None, 'priority': None, 'technical_details': None, 'feature_details': None, 'ticket_title': None, 'ticket_description': None, 'manual_review_flag': False, 'qc_feedback': [], 'processing_log': ['CSV Reader: Loaded email record E001']}, {'input_filename': 'support_emails.csv', 'source_id': 'E002', 'source_type': 'email', 'raw_text': 'Login Issue. Hi, I cannot login since the last update on my iPhone 14 (iOS 17). Please help.', 'category': None, 'confidence': None, 'priority': None, 'technical_details': None, 'feature_details': None, 'ticket_title': None, 'ticket_description': None, 'manual_review_flag': False, 'qc_feedback': [], 'processing_log': ['CSV Reader: Loaded email record E002']}, {'input_filename': 'support_emails.csv', 'source_id': 'E003', 'source_type': 'email', 'raw_text': 'Feature Request: Dark Mode. Hello team, I would really appreciate a dark mode option for night usage.', 'category': None, 'confidence': None, 'priority': None, 'technical_details': None, 'feature_details': None, 'ticket_title': None, 'ticket_description': None, 'manual_review_flag': False, 'qc_feedback': [], 'processing_log': ['CSV Reader: Loaded email record E003']}, {'input_filename': 'support_emails.csv', 'source_id': 'E004', 'source_type': 'email', 'raw_text': 'Suggestion for Improvement. It would be great if you could add calendar integration with Google Calendar.', 'category': None, 'confidence': None, 'priority': None, 'technical_details': None, 'feature_details': None, 'ticket_title': None, 'ticket_description': None, 'manual_review_flag': False, 'qc_feedback': [], 'processing_log': ['CSV Reader: Loaded email record E004']}, {'input_filename': 'support_emails.csv', 'source_id': 'E005', 'source_type': 'email', 'raw_text': 'Data Loss Problem. Formal complaint: My tasks disappeared after syncing across devices. Device: OnePlus 11, Android 13.', 'category': None, 'confidence': None, 'priority': None, 'technical_details': None, 'feature_details': None, 'ticket_title': None, 'ticket_description': None, 'manual_review_flag': False, 'qc_feedback': [], 'processing_log': ['CSV Reader: Loaded email record E005']}, {'input_filename': 'support_emails.csv', 'source_id': 'E006', 'source_type': 'email', 'raw_text': 'General Feedback. Love the app so far, works smoothly for my daily planning.', 'category': None, 'confidence': None, 'priority': None, 'technical_details': None, 'feature_details': None, 'ticket_title': None, 'ticket_description': None, 'manual_review_flag': False, 'qc_feedback': [], 'processing_log': ['CSV Reader: Loaded email record E006']}, {'input_filename': 'support_emails.csv', 'source_id': 'E007', 'source_type': 'email', 'raw_text': 'App Crash Report. App crashes randomly lol. Using Pixel 7, Android 14. Happens when editing tasks.', 'category': None, 'confidence': None, 'priority': None, 'technical_details': None, 'feature_details': None, 'ticket_title': None, 'ticket_description': None, 'manual_review_flag': False, 'qc_feedback': [], 'processing_log': ['CSV Reader: Loaded email record E007']}, {'input_filename': 'support_emails.csv', 'source_id': 'E008', 'source_type': 'email', 'raw_text': 'Feature Request. Please add recurring tasks feature. Very important for productivity.', 'category': None, 'confidence': None, 'priority': None, 'technical_details': None, 'feature_details': None, 'ticket_title': None, 'ticket_description': None, 'manual_review_flag': False, 'qc_feedback': [], 'processing_log': ['CSV Reader: Loaded email record E008']}, {'input_filename': 'support_emails.csv', 'source_id': 'E009', 'source_type': 'email', 'raw_text': 'Spam Inquiry. Check out our marketing services at www.promosite.com', 'category': None, 'confidence': None, 'priority': None, 'technical_details': None, 'feature_details': None, 'ticket_title': None, 'ticket_description': None, 'manual_review_flag': False, 'qc_feedback': [], 'processing_log': ['CSV Reader: Loaded email record E009']}]\n",
            "Raw text is --> App Crash Report. Dear Team, the app crashes on my Samsung Galaxy S21 running Android 14. Steps: Open app → tap Add Task → crash.\n",
            "Metadat is---> {}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw text is --> Login Issue. Hi, I cannot login since the last update on my iPhone 14 (iOS 17). Please help.\n",
            "Metadat is---> {}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Raw Data Login Issue. Hi, I cannot login since the last update on my iPhone 14 (iOS 17). Please help.\n",
            "\n",
            " Metadata {}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw text is --> Feature Request: Dark Mode. Hello team, I would really appreciate a dark mode option for night usage.\n",
            "Metadat is---> {}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw text is --> Suggestion for Improvement. It would be great if you could add calendar integration with Google Calendar.\n",
            "Metadat is---> {}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw text is --> Data Loss Problem. Formal complaint: My tasks disappeared after syncing across devices. Device: OnePlus 11, Android 13.\n",
            "Metadat is---> {}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw text is --> General Feedback. Love the app so far, works smoothly for my daily planning.\n",
            "Metadat is---> {}\n",
            "Raw text is --> App Crash Report. App crashes randomly lol. Using Pixel 7, Android 14. Happens when editing tasks.\n",
            "Metadat is---> {}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Raw Data App Crash Report. App crashes randomly lol. Using Pixel 7, Android 14. Happens when editing tasks.\n",
            "\n",
            " Metadata {}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw text is --> Feature Request. Please add recurring tasks feature. Very important for productivity.\n",
            "Metadat is---> {}\n",
            "Raw text is --> Spam Inquiry. Check out our marketing services at www.promosite.com\n",
            "Metadat is---> {}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E001 Unknown\n",
            "E002 Bug\n",
            "E003 Feature\n",
            "E004 Feature\n",
            "E005 Complaint\n",
            "E006 Praise\n",
            "E007 Bug\n",
            "E008 Feature\n",
            "E009 Spam\n"
          ]
        }
      ],
      "source": [
        "async def run_pipeline(csv_path: str, source_type: str):\n",
        "    records = csv_reader_agent(csv_path, source_type)\n",
        "\n",
        "    results = []\n",
        "    for state in records:\n",
        "        final_state = await feedback_graph.ainvoke(state)\n",
        "        results.append(final_state)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "\n",
        "output = await run_pipeline(\n",
        "    csv_path=\"support_emails.csv\",\n",
        "    source_type=\"email\"\n",
        "\n",
        "    #csv_path=\"app_store_reviews.csv\",\n",
        "    #source_type = \"review\"\n",
        ")\n",
        "\n",
        "for item in output:\n",
        "    print(item[\"source_id\"], item[\"category\"])\n",
        "#if __name__ == \"__main__\":\n",
        "    # output = asyncio.run(\n",
        "    #     run_pipeline(\n",
        "    #         csv_path=\"support_emails.csv\",\n",
        "    #         source_type=\"email\"   # or \"review\"\n",
        "    #     )\n",
        "    # )\n",
        "\n",
        "    # for item in output:\n",
        "    #     print(\"=\" * 50)\n",
        "    #     print(\"ID:\", item[\"source_id\"])\n",
        "    #     print(\"Category:\", item[\"category\"])\n",
        "    #     print(\"Priority:\", item[\"priority\"])\n",
        "    #     print(\"Ticket Title:\", item[\"ticket_title\"])\n",
        "    #     print(\"Manual Review:\", item[\"manual_review_flag\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Accuracy Metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_reviews = pd.read_csv(\"generated_tickets_app_store_reviews.csv\")\n",
        "df_emails = pd.read_csv(\"generated_tickets._source_email.csv\")\n",
        "\n",
        "df_all = pd.concat([df_reviews, df_emails], ignore_index=True)\n",
        "df_all.to_csv(\"generated_tickets_all.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [23, 9]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[249], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m pred \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_tickets_all.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      5\u001b[0m true \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected_classifications.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(true, pred))\n",
            "File \u001b[0;32m~/anaconda3/envs/edurekacourse/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:218\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    214\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    215\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    216\u001b[0m         )\n\u001b[1;32m    217\u001b[0m     ):\n\u001b[0;32m--> 218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    228\u001b[0m     )\n",
            "File \u001b[0;32m~/anaconda3/envs/edurekacourse/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2948\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2840\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[1;32m   2841\u001b[0m \n\u001b[1;32m   2842\u001b[0m \u001b[38;5;124;03mRead more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2944\u001b[0m \u001b[38;5;124;03m<BLANKLINE>\u001b[39;00m\n\u001b[1;32m   2945\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2947\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m attach_unique(y_true, y_pred)\n\u001b[0;32m-> 2948\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m   2950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2951\u001b[0m     labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
            "File \u001b[0;32m~/anaconda3/envs/edurekacourse/lib/python3.11/site-packages/sklearn/metrics/_classification.py:97\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     96\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[0;32m---> 97\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m     98\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     99\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/envs/edurekacourse/lib/python3.11/site-packages/sklearn/utils/validation.py:473\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    471\u001b[0m lengths \u001b[38;5;241m=\u001b[39m [_num_samples(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(lengths)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 473\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    474\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    476\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [23, 9]"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "pred = pd.read_csv(\"generated_tickets_all.csv\")[\"category\"]\n",
        "true = pd.read_csv(\"expected_classifications.csv\")[\"category\"]\n",
        "\n",
        "print(classification_report(true, pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "TensorFlow with GPU",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "edurekacourse",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
